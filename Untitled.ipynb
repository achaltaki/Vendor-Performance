{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c709aad-a4e8-4652-a5cd-6c6947348ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c95a04-8a44-44a8-9a57-7573ffccadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine =create_engine('sqlite:///inventory.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a90fc-de71-4e2e-ba27-a209a2abe932",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(r'C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data'):\n",
    "    if '.csv' in file:\n",
    "        df= pd.read_csv(r'C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data/'+file)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12a531-9889-4d6b-9e41-4ad40adcafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ba18a8-dfce-4367-9dc4-e14a3eb7a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in folder: ['.ipynb_checkpoints', 'begin_inventory.csv', 'end_inventory.csv', 'purchases.csv', 'purchase_prices.csv', 'sales.csv', 'vendor_invoice.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = r'C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data'\n",
    "print(\"Files in folder:\", os.listdir(folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec3f1f9-7709-4a41-b33e-7d03e0be19d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Ingesting `begin_inventory` from C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data\\begin_inventory.csv in chunks of 100000 rows...\n",
      "‚úÖ Completed: begin_inventory\n",
      "üîÑ Ingesting `end_inventory` from C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data\\end_inventory.csv in chunks of 100000 rows...\n",
      "‚úÖ Completed: end_inventory\n",
      "üîÑ Ingesting `purchases` from C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data\\purchases.csv in chunks of 100000 rows...\n",
      "‚úÖ Completed: purchases\n",
      "üîÑ Ingesting `purchase_prices` from C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data\\purchase_prices.csv in chunks of 100000 rows...\n",
      "‚úÖ Completed: purchase_prices\n",
      "üîÑ Ingesting `sales` from C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data\\sales.csv in chunks of 100000 rows...\n",
      "‚úÖ Completed: sales\n",
      "üîÑ Ingesting `vendor_invoice` from C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data\\vendor_invoice.csv in chunks of 100000 rows...\n",
      "‚úÖ Completed: vendor_invoice\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging \n",
    "import time\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s-%(levelname)s-%(message)s\",\n",
    "    filemode=\"a\"\n",
    ")\n",
    "def load_raw_data():\n",
    "    start=time.time()\n",
    "    for file in os.listdir(''):\n",
    "        if '.csv' in file:\n",
    "            df=pd.read_csv('/'+file)\n",
    "            logging.info(f'Ingesting {file} in db')\n",
    "            ingest_db_chunked(df,file[:-4],engine)\n",
    "            end=time.time()\n",
    "            total_time=(end-start)/60\n",
    "            logging.info('----------Ingestion complete----------')\n",
    "            logging.info(f'\\nTotal Time Taken:{total_time}minutes')\n",
    "    \n",
    "\n",
    "# Database setup: change path or use MySQL/PostgreSQL connection if needed\n",
    "db_path = 'sqlite:///C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\inventory_db.sqlite'\n",
    "engine = create_engine(db_path)\n",
    "\n",
    "# Folder containing CSV files\n",
    "folder = r'C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data'\n",
    "\n",
    "# Ingest function with chunking\n",
    "def ingest_db_chunked(file_path, table_name, engine, chunksize=100000):\n",
    "    print(f\"üîÑ Ingesting `{table_name}` from {file_path} in chunks of {chunksize} rows...\")\n",
    "    first_chunk = True\n",
    "    try:\n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "            chunk.to_sql(\n",
    "                table_name,\n",
    "                con=engine,\n",
    "                if_exists='replace' if first_chunk else 'append',\n",
    "                index=False\n",
    "            )\n",
    "            first_chunk = False\n",
    "        print(f\"‚úÖ Completed: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed: {table_name} | Error: {e}\")\n",
    "\n",
    "# Loop through files in folder\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder, file)\n",
    "        table_name = os.path.splitext(file)[0]\n",
    "        ingest_db_chunked(file_path, table_name, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f447b45-4f79-471b-80d8-be9d9c92d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_db(df,table_name,engine):\n",
    "    df.to_sql(table_name,con=engine,if_exists='replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e233d4db-15bf-4357-8533-4cb756acd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Ensure the logs directory exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"\n",
    ")\n",
    "\n",
    "# Create database engine (SQLite)\n",
    "engine = create_engine('sqlite:///C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\inventory_db.sqlite')\n",
    "\n",
    "# Folder containing CSV files\n",
    "folder = r'C:\\\\Users\\\\Hp\\\\Desktop\\\\nvendor\\\\data'\n",
    "\n",
    "# Function to ingest large CSVs in chunks\n",
    "def ingest_db_chunked(file_path, table_name, engine, chunksize=100000):\n",
    "    logging.info(f\"Started ingesting `{table_name}` from {file_path}\")\n",
    "    first_chunk = True\n",
    "    try:\n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "            chunk.to_sql(\n",
    "                table_name,\n",
    "                con=engine,\n",
    "                if_exists='replace' if first_chunk else 'append',\n",
    "                index=False\n",
    "            )\n",
    "            first_chunk = False\n",
    "        logging.info(f\"‚úÖ Completed: {table_name}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error ingesting {table_name}: {e}\")\n",
    "\n",
    "# Main function to load all raw data files\n",
    "def load_raw_data():\n",
    "    start = time.time()\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            table_name = os.path.splitext(file)[0]\n",
    "            logging.info(f\"Ingesting file: {file}\")\n",
    "            ingest_db_chunked(file_path, table_name, engine)\n",
    "\n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60\n",
    "    logging.info('----------Ingestion complete----------')\n",
    "    logging.info(f'Total Time Taken: {total_time:.2f} minutes')\n",
    "\n",
    "# Call the function to run the ingestion\n",
    "load_raw_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d117239-0959-4c6f-b4ef-01dc3df8d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
